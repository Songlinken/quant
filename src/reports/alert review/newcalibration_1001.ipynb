{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sqian/.pyenv/versions/3.7.0/envs/env_370/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import os; \n",
    "import pandas as pd; pd.set_option('mode.chained_assignment',None)\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "import re\n",
    "import xlrd\n",
    "import statistics as stat\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "from random import sample\n",
    "\n",
    "from src.data_models.SmartsCsvDataModel import SmartsCsvDataModel\n",
    "from src.data_models.smartshelper import metrics, fixNum, unSMART, cparty, wtf\n",
    "from src.data_models.SmartsDataModel import SmartsDataModel\n",
    "from src.utility.DataModelUtility import execute_query_data_frame\n",
    "from src.data_models.SmartsDataModel import SmartsDataModel\n",
    "from src.data_models.UPMhelper import UPMalerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.9999\n",
    "qv = 0.999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Collecting Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> type fixed, kept 1284 rows, 13 columns\n"
     ]
    }
   ],
   "source": [
    "alerts0 = fixNum(unSMART(pd.read_excel('~/Documents/vmfldr/smarts1_2019JanMay.xlsx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts1001 = alerts0.loc[alerts0['AlertCode'] == 1001,['AlertCode','LongText','InstrumentName']]\n",
    "alerts1001['LongText2'] = alerts1001['LongText'].str.extract('\\D+(Price Change.+)Bid.+',expand=True)\n",
    "\n",
    "alerts1001['min05'] = alerts1001['LongText2'].str.findall('Price\\D+(\\d+\\D+)\\sis').apply(lambda x: '5 minutes' in x) * 1\n",
    "alerts1001['min10'] = alerts1001['LongText2'].str.findall('Price\\D+(\\d+\\D+)\\sis').apply(lambda x: '10 minutes' in x) * 1\n",
    "alerts1001['min60'] = alerts1001['LongText2'].str.findall('Price\\D+(\\d+\\D+)\\sis').apply(lambda x: '1 hour' in x) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alerts0.groupby(['AlertCode',alerts0['Datetime'].dt.month]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regextext2 = 'Price Change\\D+(\\d+\\s[a-z]+)[^\\(]+\\(([\\d.]+)%\\)[^\\(]+\\(([\\d.]+)%\\)\\s*'\n",
    "\n",
    "alerts1001_rematch = alerts1001['LongText2'].str.extractall(regextext2)\n",
    "alerts1001_rematch_5m = alerts1001_rematch.loc[alerts1001_rematch[0]=='5 minutes',[1,2]].astype(float).reset_index().set_index('level_0')[[1,2]].rename(columns={1:'val_5m',2:'bm_5m'})\n",
    "alerts1001_rematch_10m = alerts1001_rematch.loc[alerts1001_rematch[0]=='10 minutes',[1,2]].astype(float).reset_index().set_index('level_0')[[1,2]].rename(columns={1:'val_10m',2:'bm_10m'})\n",
    "alerts1001_rematch_60m = alerts1001_rematch.loc[alerts1001_rematch[0]=='1 hour',[1,2]].astype(float).reset_index().set_index('level_0')[[1,2]].rename(columns={1:'val_60m',2:'bm_60m'})\n",
    "\n",
    "alerts1001_parsed = pd.concat([alerts1001['InstrumentName'],alerts1001_rematch_5m, alerts1001_rematch_10m, alerts1001_rematch_60m], axis=1)\n",
    "alerts1001_mean = alerts1001_parsed.groupby('InstrumentName').mean()/100\n",
    "alerts1001_count = alerts1001_parsed.groupby('InstrumentName').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Constructing Singleton\n",
      "INFO:root:Using global configuration /Users/sqian/msv.yaml.\n",
      "INFO:root:Completed loading configuration.\n",
      "INFO:paramiko.transport:Connected (version 2.0, client OpenSSH_7.4p1)\n",
      "INFO:paramiko.transport:Authentication (publickey) successful!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh_connect 0:00:01.081041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded dataframe with 3271817 rows in 0:01:12.157880.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        SELECT created, price, quantity, trading_pair\n",
    "        from order_fill_event\n",
    "        where created::date between '2019-01-01' and '2019-05-31'\n",
    "        \"\"\"\n",
    "\n",
    "data0 = execute_query_data_frame(query,'engine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) UPM Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data0.sort_values('created')\n",
    "data1['time05'] = data1['created'] + datetime.timedelta(minutes=5)\n",
    "data1['time10'] = data1['created'] + datetime.timedelta(minutes=10)\n",
    "data1['time60'] = data1['created'] + datetime.timedelta(minutes=60)\n",
    "table1 = data1[['created','price','trading_pair']]\n",
    "# table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(200%,);{BTCUSD,(7.62%,)};{ZECUSD,(8.3%,)};{ETHUSD,(8.89%,)};{BCHUSD,(11.56%,)};{ETHBTC,(13.08%,)};{LTCUSD,(15.16%,)};{ZECETH,(21.92%,)};{ZECBTC,(33.42%,)};{LTCBTC,(67.7%,)};{LTCETH,(105.9%,)}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2 = data1.drop(columns=['created','quantity']).rename(columns={'time05':'created','price':'price2'})\n",
    "df_merge_asof = pd.merge_asof(table1, table2, on='created', by='trading_pair')\n",
    "df_merge_asof['change'] = abs(df_merge_asof['price2']/df_merge_asof['price']-1)\n",
    "temp = df_merge_asof.dropna(how='any').groupby('trading_pair').apply(lambda x: x.quantile(q)).sort_values('change')\n",
    "temp2 = pd.concat([temp,alerts1001_mean['val_5m']],axis=1,sort=False)\n",
    "temp2['room'] = temp2['change'] - temp2['val_5m']\n",
    "\n",
    "syntax = (round(temp2['change']*100,2)).clip(0,200).astype(str)+'%'\n",
    "syntax2 = syntax.loc[syntax != '200.0%'].reset_index();syntax2\n",
    "syntax2['syntax'] = '{' + syntax2['index'] + ',(' + syntax2['change'] + ',)}'\n",
    "syntax_05m = '(200%,);'+';'.join(syntax2['syntax'])\n",
    "syntax_05m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(200%,);{ZECUSD,(8.33%,)};{ETHUSD,(9.97%,)};{BTCUSD,(11.67%,)};{BCHUSD,(12.87%,)};{ETHBTC,(13.11%,)};{LTCUSD,(19.06%,)};{ZECETH,(21.92%,)};{ZECBTC,(33.42%,)};{LTCBTC,(67.7%,)};{LTCETH,(105.9%,)}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2 = data1.drop(columns=['created','quantity']).rename(columns={'time10':'created','price':'price2'})\n",
    "df_merge_asof = pd.merge_asof(table1, table2, on='created', by='trading_pair')\n",
    "df_merge_asof['change'] = abs(df_merge_asof['price2']/df_merge_asof['price']-1)\n",
    "temp = df_merge_asof.dropna(how='any').groupby('trading_pair').apply(lambda x: x.quantile(q)).sort_values('change')\n",
    "temp2 = pd.concat([temp,alerts1001_mean[['val_10m']]],axis=1,sort=False)\n",
    "temp2['room'] = temp2['change'] - temp2['val_10m']\n",
    "\n",
    "syntax = (round(temp2['change']*100,2)).clip(0,200).astype(str)+'%'\n",
    "syntax2 = syntax.loc[syntax != '200.0%'].reset_index();syntax2\n",
    "syntax2['syntax'] = '{' + syntax2['index'] + ',(' + syntax2['change'] + ',)}'\n",
    "syntax_10m = '(200%,);'+';'.join(syntax2['syntax'])\n",
    "syntax_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(200%,);{ETHBTC,(11.14%,)};{ZECUSD,(13.08%,)};{ZECBTC,(14.97%,)};{ETHUSD,(17.57%,)};{BTCUSD,(17.98%,)};{BCHUSD,(20.11%,)};{ZECETH,(21.95%,)};{LTCUSD,(22.16%,)};{LTCBTC,(67.75%,)};{LTCETH,(105.9%,)};{BCHBTC,(153.65%,)};{ZECBCH,(165.11%,)}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2 = data1.drop(columns=['created','quantity']).rename(columns={'time60':'created','price':'price2'})\n",
    "df_merge_asof = pd.merge_asof(table1, table2, on='created', by='trading_pair')\n",
    "df_merge_asof['change'] = abs(df_merge_asof['price2']/df_merge_asof['price']-1)\n",
    "temp = df_merge_asof.dropna(how='any').groupby('trading_pair').apply(lambda x: x.quantile(q)).sort_values('change')\n",
    "temp2 = pd.concat([temp,alerts1001_mean[['val_60m']]],axis=1,sort=False)\n",
    "temp2['room'] = temp2['change'] - temp2['val_60m']\n",
    "\n",
    "syntax = (round(temp2['change']*100,2)).clip(0,200).astype(str)+'%'\n",
    "syntax2 = syntax.loc[syntax != '200.0%'].reset_index();syntax2\n",
    "syntax2['syntax'] = '{' + syntax2['index'] + ',(' + syntax2['change'] + ',)}'\n",
    "syntax_60m = '(200%,);'+';'.join(syntax2['syntax'])\n",
    "syntax_60m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) UVM Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(data0,index='created',columns='trading_pair',values='quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvm = pd.DataFrame()\n",
    "\n",
    "for i in temp.columns.tolist():\n",
    "    temp2 = pd.DataFrame(temp[i].dropna())\n",
    "    temp2['rolling05'] = temp2[i].rolling('5min').sum()\n",
    "    temp2['rolling10'] = temp2[i].rolling('10min').sum()\n",
    "    temp2['rolling60'] = temp2[i].rolling('60min').sum()\n",
    "    temp3 = pd.DataFrame(temp2.quantile(qv)).transpose()[['rolling05','rolling10','rolling60']]\n",
    "    temp3.index = [i]\n",
    "    uvm = uvm.append(temp3.reset_index(),sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uvm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7725f4416196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muvm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rolling05'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'uvm' is not defined"
     ]
    }
   ],
   "source": [
    "uvm2 = uvm.set_index('index').astype(int).sort_values('rolling05',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1,);{ETHUSD,(x12756,)};{LTCUSD,(x11712,)};{LTCBTC,(x6962,)};{ZECUSD,(x4108,)};{ETHBTC,(x3601,)};{ZECBTC,(x3366,)};{BCHUSD,(x1434,)};{LTCETH,(x1123,)};{BTCUSD,(x734,)};{BCHBTC,(x700,)};{ZECETH,(x684,)};{ZECBCH,(x424,)};{LTCBCH,(x318,)};{BCHETH,(x224,)};{ZECLTC,(x56,)}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax = uvm2['rolling05'].reset_index()\n",
    "syntax['syntax'] = '{' + syntax['index'] + ',(x' + syntax['rolling05'].astype(str) + ',)}'\n",
    "syntaxprint = '(x1,);'+';'.join(syntax['syntax'])\n",
    "syntaxprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1,);{ETHUSD,(x19819,)};{LTCUSD,(x15371,)};{LTCBTC,(x9034,)};{ZECUSD,(x5940,)};{ETHBTC,(x4132,)};{ZECBTC,(x3425,)};{BCHUSD,(x1970,)};{LTCETH,(x1310,)};{BTCUSD,(x1201,)};{BCHBTC,(x1267,)};{ZECETH,(x684,)};{ZECBCH,(x424,)};{LTCBCH,(x385,)};{BCHETH,(x264,)};{ZECLTC,(x61,)}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax = uvm2['rolling10'].reset_index()\n",
    "syntax['syntax'] = '{' + syntax['index'] + ',(x' + syntax['rolling10'].astype(str) + ',)}'\n",
    "syntaxprint = '(x1,);'+';'.join(syntax['syntax'])\n",
    "syntaxprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1,);{ETHUSD,(x21388,)};{LTCUSD,(x33198,)};{LTCBTC,(x9176,)};{ZECUSD,(x10307,)};{ETHBTC,(x7806,)};{ZECBTC,(x3807,)};{BCHUSD,(x3107,)};{LTCETH,(x2473,)};{BTCUSD,(x2786,)};{BCHBTC,(x1807,)};{ZECETH,(x1001,)};{ZECBCH,(x504,)};{LTCBCH,(x385,)};{BCHETH,(x425,)};{ZECLTC,(x61,)}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax = uvm2['rolling60'].reset_index()\n",
    "syntax['syntax'] = '{' + syntax['index'] + ',(x' + syntax['rolling60'].astype(str) + ',)}'\n",
    "syntaxprint = '(x1,);'+';'.join(syntax['syntax'])\n",
    "syntaxprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alertsnew = fixNum(unSMART(pd.read_excel('~/Documents/vmfldr/newcalibration_71.xlsx')))\n",
    "# alertsnew2 = alertsnew.loc[alertsnew['Datetime'].dt.month > 3]\n",
    "# pd.DataFrame(alertsnew2.groupby([alertsnew2['Datetime'].dt.month,'AlertCode','ShortText']).count()['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alertsnew = fixNum(unSMART(pd.read_excel('~/Documents/vmfldr/smarts2.2_2019AprMay.xlsx')))\n",
    "# alertsnew2 = alertsnew.loc[alertsnew['Datetime'].dt.month > 3]\n",
    "# pd.DataFrame(alertsnew2.groupby([alertsnew2['Datetime'].dt.month,'AlertCode','ShortText']).count()['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
